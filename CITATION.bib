@article{kang2017bayesian,
  title={A Bayesian double fusion model for resting-state brain connectivity using joint functional and structural data},
  author={Kang, Hakmook and Ombao, Hernando and Fonnesbeck, Christopher and Ding, Zhaohua and Morgan, Victoria L},
  journal={Brain connectivity},
  volume={7},
  number={4},
  pages={219--227},
  year={2017},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}

@article{LI2016366,
title = {A review on Gaussian Process Latent Variable Models},
journal = {CAAI Transactions on Intelligence Technology},
volume = {1},
number = {4},
pages = {366-376},
year = {2016},
issn = {2468-2322},
doi = {https://doi.org/10.1016/j.trit.2016.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S2468232216300828},
author = {Ping Li and Songcan Chen},
keywords = {GPLVM, Non-parametric method, Gaussian process},
abstract = {Gaussian Process Latent Variable Model (GPLVM), as a flexible bayesian non-parametric modeling method, has been extensively studied and applied in many learning tasks such as Intrusion Detection, Image Reconstruction, Facial Expression Recognition, Human pose estimation and so on. In this paper, we give a review and analysis for GPLVM and its extensions. Firstly, we formulate basic GPLVM and discuss its relation to Kernel Principal Components Analysis. Secondly, we summarize its improvements or variants and propose a taxonomy of GPLVM related models in terms of the various strategies that be used. Thirdly, we provide the detailed formulations of the main GPLVMs that extensively developed based on the strategies described in the paper. Finally, we further give some challenges in next researches of GPLVM.}
}

@article{hoffman2014no,
  title={The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.},
  author={Hoffman, Matthew D and Gelman, Andrew and others},
  journal={J. Mach. Learn. Res.},
  volume={15},
  number={1},
  pages={1593--1623},
  year={2014}
}

@article{robert2018accelerating,
  title={Accelerating MCMC algorithms},
  author={Robert, Christian P and Elvira, V{\'\i}ctor and Tawn, Nick and Wu, Changye},
  journal={Wiley Interdisciplinary Reviews: Computational Statistics},
  volume={10},
  number={5},
  pages={e1435},
  year={2018},
  publisher={Wiley Online Library}
}

@article{kang2017bayesian,
  title={A Bayesian double fusion model for resting-state brain connectivity using joint functional and structural data},
  author={Kang, Hakmook and Ombao, Hernando and Fonnesbeck, Christopher and Ding, Zhaohua and Morgan, Victoria L},
  journal={Brain connectivity},
  volume={7},
  number={4},
  pages={219--227},
  year={2017},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}


@InProceedings{pmlr-v22-luttinen12,
  title = 	 {Efficient Gaussian Process Inference for Short-Scale Spatio-Temporal Modeling},
  author = 	 {Luttinen, Jaakko and Ilin, Alexander},
  booktitle = 	 {Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {741--750},
  year = 	 {2012},
  editor = 	 {Lawrence, Neil D. and Girolami, Mark},
  volume = 	 {22},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {La Palma, Canary Islands},
  month = 	 {21--23 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v22/luttinen12/luttinen12.pdf},
  url = 	 {https://proceedings.mlr.press/v22/luttinen12.html},
  abstract = 	 {This paper presents an efficient Gaussian process inference scheme for modeling shortscale phenomena in spatio-temporal datasets. Our model uses a sum of separable, compactly supported covariance functions, which yields a full covariance matrix represented in terms of small sparse matrices operating either on the spatial or temporal domain. The proposed inference procedure is based on Gibbs sampling, in which samples from the conditional distribution of the latent function values are obtained by applying a simple linear transformation to samples drawn from the joint distribution of the function values and the observations. We make use of the proposed model structure and the conjugate gradient method to compute the required transformation. In the experimental part, the proposed algorithm is compared to the standard approach using the sparse Cholesky decomposition and it is shown to be much faster and computationally feasible for 100-1000 times larger datasets. We demonstrate the advantages of the proposed method in the problem of reconstructing sea surface temperature, which requires processing of a real-world dataset with 10^6 observations.}
}

@article{wang2020bayesian,
  title={A bayesian approach to examining default mode network functional connectivity and cognitive performance in major depressive disorder},
  author={Wang, Rui and Albert, Kimberly M and Taylor, Warren D and Boyd, Brian D and Blaber, Justin and Lyu, Ilwoo and Landman, Bennett A and Vega, Jennifer and Shokouhi, Sepideh and Kang, Hakmook},
  journal={Psychiatry Research: Neuroimaging},
  volume={301},
  pages={111102},
  year={2020},
  publisher={Elsevier}
}
